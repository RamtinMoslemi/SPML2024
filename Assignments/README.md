# Assignments 
This course had six assignments.

| \# | Topic |
| :--------: | :---: |
| 1 | Neural Networks |
| 2 | CNNs and FGSM |
| 3 | PGD and CW Attacks |
| 4 | UAP and JbDA |
| 5 | NES and Poisoning |
| 6 | DP and LLMs |

## Papers 
| HW\# | Paper |
| :--: | :---: | 
| HW4 | [Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks](https://arxiv.org/pdf/1809.02861)<br>[Delving Into Transferable Adversarial Examples and Black-Box Attacks](https://arxiv.org/pdf/1611.02770)<br>[Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors](https://arxiv.org/pdf/1807.07978) |
| HW6 | [Jailbreaking Black Box Large Language Models in Twenty Queries](https://arxiv.org/abs/2310.08419)<br>[AutoDAN: Interpertable Gradient-Based Adversarial Attacks on Large Language Models](https://arxiv.org/abs/2310.15140v2)<br>[SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks](https://arxiv.org/pdf/2310.03684) |

## 6. Differential Privacy, Large Language Models
