# RIML
Adversarial Robust Learning and its Generalization Issues 

## Readings
Following papers are about **Neural Tangent Kernels** (NTK):
1.  [Neural Tangent Kernel: Convergence and Generalization in Neural Networks](https://arxiv.org/abs/1806.07572)
2.  [Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent](https://arxiv.org/abs/1902.06720)
3.  [Deep Learning Versus Kernel Learning: An Empirical Study of Loss Landscape Geometry and the Time Evolution of the Neural Tangent Kernel](https://arxiv.org/abs/2010.15110)
4.  [What Can the Neural Tangent Kernel Tell Us About Adversarial Robustness?](https://arxiv.org/abs/2210.05577)
5.  [Evolution of Neural Tangent Kernels under Benign and Adversarial Training](https://arxiv.org/abs/2210.12030)
6.  [Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach](https://arxiv.org/abs/2310.06112)
7.  [Rethinking Adversarial Training with Neural Tangent Kernel](https://arxiv.org/abs/2312.02236)

Following papers are about miscellaneous topics such as **Robust Overfitting**, **Adaptive Attacks**, and more:
1.  [Adversarial Machine Learning at Scale](https://arxiv.org/abs/1611.01236)
2.  [The Space of Transferable Adversarial Examples](https://arxiv.org/abs/1704.03453)
3.  [Ensemble Adversarial Training: Attacks and Defenses](https://arxiv.org/abs/1705.07204)
4.  [Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates](https://arxiv.org/abs/1708.07120)
5.  [Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning](https://arxiv.org/abs/1712.03141)
6.  [On Evaluating Adversarial Robustness](https://arxiv.org/abs/1902.06705)
7.  [Adversarial Training for Free!](https://arxiv.org/abs/1904.12843)
8.  [On Adaptive Attacks to Adversarial Example Defenses](https://arxiv.org/abs/2002.08347)
9.  [Overfitting in Adversarially Robust Deep Learning](https://arxiv.org/abs/2002.11569)

Following papers are about **Catastrophic Overfitting** (CO):

1.  [Fast is Better Than Free: Revisiting Adversarial Training](https://arxiv.org/abs/2001.03994)
2.  [Towards Understanding Fast Adversarial Training](https://arxiv.org/abs/2006.03089)
3.  [Understanding and Improving Fast Adversarial Training](https://arxiv.org/abs/2007.02617)
4.  [Understanding Catastrophic Overfitting in Single-Step Adversarial Training](https://arxiv.org/abs/2010.01799)
5.  [ZeroGrad: Mitigating and Explaining Catastrophic Overfitting in FGSM Adversarial Training](https://arxiv.org/abs/2103.15476)
6.  [Reliably Fast Adversarial Training via Latent Adversarial Perturbation](https://arxiv.org/abs/2104.01575)
7.  [Understanding Catastrophic Overfitting in Adversarial Training](https://arxiv.org/abs/2105.02942)
8.  [Boosting Fast Adversarial Training with Learnable Adversarial Initialization](https://arxiv.org/abs/2110.05007)
9.  [Subspace Adversarial Training](https://arxiv.org/abs/2111.12229)
10. [Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization](https://arxiv.org/abs/2112.12376)
11. [Make Some Noise: Reliable and Efficient Single-Step Adversarial Training](https://arxiv.org/abs/2202.01181)
12. [Catastrophic Overfitting Can Be Induced with Discriminative Non-Robust Features](https://arxiv.org/abs/2206.08242)
13. [Efficient Local Linearity Regularization to Overcome Catastrophic Overfitting](https://arxiv.org/abs/2401.11618)
