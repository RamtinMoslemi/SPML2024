# RIML
Adversarial Robust Learning and its Generalization Issues 

## Readings
Following papers are about **Neural Tangent Kernels** (NTK):
- [Neural Tangent Kernel: Convergence and Generalization in Neural Networks](https://arxiv.org/abs/1806.07572)
- [Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent](https://arxiv.org/abs/1902.06720)
- [Deep Learning Versus Kernel Learning: An Empirical Study of Loss Landscape Geometry and the Time Evolution of the Neural Tangent Kernel](https://arxiv.org/abs/2010.15110)
- [Every Model Learned by Gradient Descent Is Approximately a Kernel Machine](https://arxiv.org/abs/2012.00152)
- [Fast Finite Width Neural Tangent Kernel](https://arxiv.org/abs/2206.08720)
- [What Can the Neural Tangent Kernel Tell Us About Adversarial Robustness?](https://arxiv.org/abs/2210.05577)
- [Evolution of Neural Tangent Kernels under Benign and Adversarial Training](https://arxiv.org/abs/2210.12030)
- [Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach](https://arxiv.org/abs/2310.06112)
- [Rethinking Adversarial Training with Neural Tangent Kernel](https://arxiv.org/abs/2312.02236)

Following papers are about miscellaneous topics such as **Robust Overfitting**, **Adaptive Attacks**, and more:
- [Adversarial Machine Learning at Scale](https://arxiv.org/abs/1611.01236)
- [The Space of Transferable Adversarial Examples](https://arxiv.org/abs/1704.03453)
- [Ensemble Adversarial Training: Attacks and Defenses](https://arxiv.org/abs/1705.07204)
- [Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates](https://arxiv.org/abs/1708.07120)
- [Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning](https://arxiv.org/abs/1712.03141)
- [On Evaluating Adversarial Robustness](https://arxiv.org/abs/1902.06705)
- [Adversarial Training for Free!](https://arxiv.org/abs/1904.12843)
- [On Adaptive Attacks to Adversarial Example Defenses](https://arxiv.org/abs/2002.08347)
- [Overfitting in Adversarially Robust Deep Learning](https://arxiv.org/abs/2002.11569)
- [Exploring Memorization in Adversarial Training](https://arxiv.org/abs/2106.01606)

Following papers are about **Catastrophic Overfitting** (CO):

- [Fast is Better Than Free: Revisiting Adversarial Training](https://arxiv.org/abs/2001.03994)
- [Towards Understanding Fast Adversarial Training](https://arxiv.org/abs/2006.03089)
- [Understanding and Improving Fast Adversarial Training](https://arxiv.org/abs/2007.02617)
- [Understanding Catastrophic Overfitting in Single-Step Adversarial Training](https://arxiv.org/abs/2010.01799)
- [ZeroGrad: Mitigating and Explaining Catastrophic Overfitting in FGSM Adversarial Training](https://arxiv.org/abs/2103.15476)
- [Reliably Fast Adversarial Training via Latent Adversarial Perturbation](https://arxiv.org/abs/2104.01575)
- [Understanding Catastrophic Overfitting in Adversarial Training](https://arxiv.org/abs/2105.02942)
- [Boosting Fast Adversarial Training with Learnable Adversarial Initialization](https://arxiv.org/abs/2110.05007)
- [Subspace Adversarial Training](https://arxiv.org/abs/2111.12229)
- [Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization](https://arxiv.org/abs/2112.12376)
- [Make Some Noise: Reliable and Efficient Single-Step Adversarial Training](https://arxiv.org/abs/2202.01181)
- [Catastrophic Overfitting Can Be Induced with Discriminative Non-Robust Features](https://arxiv.org/abs/2206.08242)
- [Efficient Local Linearity Regularization to Overcome Catastrophic Overfitting](https://arxiv.org/abs/2401.11618)



# Bachelors Thesis
Transferability of Distributional Robustness in Knowledge Distillation

## Readings
Following papers are about **Distributional Robustness**:
<!-- 
- [Data-driven Distributionally Robust Optimization Using the Wasserstein Metric: Performance Guarantees and Tractable Reformulations](https://arxiv.org/abs/1505.05116) 
- [Wasserstein Distributionally Robust Optimization: Theory and Applications in Machine Learning](https://arxiv.org/abs/1908.08729)
-->
- [Certifying Some Distributional Robustness with Principled Adversarial Training](https://arxiv.org/abs/1710.10571)
- [Generalised Lipschitz Regularisation Equals Distributional Robustness](https://arxiv.org/abs/2002.04197)
- [Adversarial Distributional Training for Robust Deep Learning](https://arxiv.org/abs/2002.05999)
- [On Robustness and Transferability of Convolutional Neural Networks](https://arxiv.org/abs/2007.08558)
- [Distributional Robustness Loss for Long-tail Learning](https://arxiv.org/abs/2104.03066)
- [Distributionally Robust Learning](https://arxiv.org/abs/2108.08993)
- [A Unified Wasserstein Distributional Robustness Framework for Adversarial Training](https://arxiv.org/abs/2202.13437)
- [Explicit Tradeoffs between Adversarial and Natural Distributional Robustness](https://arxiv.org/abs/2209.07592)

Following papers are about **Knowledge Distillation**:
- [Variational Information Distillation for Knowledge Transfer](https://arxiv.org/abs/1904.05835)
- [Adversarially Robust Distillation](https://arxiv.org/abs/1905.09747)
- [Revisiting Adversarial Robustness Distillation: Robust Soft Labels Make Student Better](https://arxiv.org/abs/2108.07969)
- [How and When Adversarial Robustness Transfers in Knowledge Distillation?](https://arxiv.org/abs/2110.12072)
- [On the benefits of knowledge distillation for adversarial robustness](https://arxiv.org/abs/2203.07159)

